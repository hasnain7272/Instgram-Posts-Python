import os
import requests
import base64
import time
from urllib.parse import quote
import google.generativeai as genai
import subprocess
import tempfile
import json
import random
import asyncio
import edge_tts

from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google.oauth2.credentials import Credentials
from google_auth_httplib2 import AuthorizedHttp

class TrulyAIReelGenerator:
    def __init__(self, google_api_key: str = None, openai_api_key: str = None,
                 cloudinary_cloud_name: str = None, cloudinary_api_key: str = None, 
                 cloudinary_api_secret: str = None, cloudinary_upload_preset: str = None,
                 replicate_api_token: str = None, huggingface_api_token: str = None):
        """Initialize AI Reel Generator with Voiceover Capabilities"""
        self.google_api_key = google_api_key
        self.openai_api_key = openai_api_key
        
        # Cloudinary credentials
        self.cloudinary_cloud_name = cloudinary_cloud_name
        self.cloudinary_api_key = cloudinary_api_key
        self.cloudinary_api_secret = cloudinary_api_secret
        self.cloudinary_upload_preset = cloudinary_upload_preset
        
        # Image gen tokens
        self.replicate_api_token = replicate_api_token
        self.huggingface_api_token = huggingface_api_token
        
        # Enhancement flag
        self.enable_enhancement = os.getenv('ENABLE_CLOUDINARY_ENHANCE', 'true').lower() == 'true'
        if self.enable_enhancement:
            if not all([cloudinary_cloud_name, cloudinary_api_key, cloudinary_api_secret]):
                self.enable_enhancement = False
        
        if google_api_key:
            genai.configure(api_key=google_api_key)
        
        self.has_drawtext = self._check_drawtext_support()
        
        # Voice Settings (Male: en-US-ChristopherNeural, Female: en-US-AriaNeural)
        self.voice_id = "en-US-ChristopherNeural" 
        
        self.music_library = {
            'energetic': [
                'https://www.bensound.com/bensound-music/bensound-energy.mp3',
                'https://www.bensound.com/bensound-music/bensound-highoctane.mp3',
            ],
            'calm': [
                'https://www.bensound.com/bensound-music/bensound-relaxing.mp3',
            ],
            'upbeat': [
                'https://www.bensound.com/bensound-music/bensound-sunny.mp3',
                'https://www.bensound.com/bensound-music/bensound-creativeminds.mp3',
            ],
            'intense': [
                'https://www.bensound.com/bensound-music/bensound-epic.mp3',
            ],
            'chill': [
                'https://www.bensound.com/bensound-music/bensound-jazzyfrenchy.mp3',
            ]
        }

    def _check_drawtext_support(self) -> bool:
        """Check if FFmpeg has drawtext filter support"""
        try:
            result = subprocess.run(['ffmpeg', '-filters'], capture_output=True, text=True, timeout=5)
            return 'drawtext' in result.stdout
        except:
            return False

    def _huggingface_text_generate(self, prompt: str) -> str:
        """Generate JSON using HF (OpenAI Compatible)"""
        if not self.huggingface_api_token:
            raise Exception("Hugging Face API token required")
        
        API_URL = "https://router.huggingface.co/v1/chat/completions"
        headers = {"Authorization": f"Bearer {self.huggingface_api_token}", "Content-Type": "application/json"}
        
        payload = {
            "model": "Qwen/Qwen2.5-72B-Instruct", # Using a smarter model for logic
            "messages": [
                {"role": "system", "content": "You are a professional video scripter. Return ONLY valid JSON."},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 4096,
            "temperature": 0.7
        }
        
        for attempt in range(3):
            try:
                response = requests.post(API_URL, headers=headers, json=payload, timeout=90)
                if response.status_code == 200:
                    return response.json()['choices'][0]['message']['content']
                time.sleep(3)
            except:
                time.sleep(3)
        
        raise Exception("HF Text Gen failed")

    async def _generate_voiceover_async(self, text: str, output_path: str):
        """Async wrapper for edge-tts"""
        communicate = edge_tts.Communicate(text, self.voice_id)
        await communicate.save(output_path)

    def _generate_voiceover(self, text: str, output_path: str):
        """Synchronous wrapper for voiceover generation"""
        try:
            asyncio.run(self._generate_voiceover_async(text, output_path))
            return True
        except Exception as e:
            print(f"‚ö†Ô∏è TTS Error: {e}")
            return False

    def _get_audio_duration(self, audio_path: str) -> float:
        """Get exact duration of generated audio"""
        try:
            cmd = ['ffprobe', '-v', 'error', '-show_entries', 'format=duration', 
                   '-of', 'default=noprint_wrappers=1:nokey=1', audio_path]
            result = subprocess.run(cmd, capture_output=True, text=True)
            return float(result.stdout.strip())
        except:
            return 3.0 # Fallback

    def generate_reel(self, niche: str, num_images: int = 5, duration: int = 15):
        """Generate AI Reel with Voiceover and Dynamic Pacing"""
        print(f"üé¨ Generating Storytelling Reel for: {niche}")

        base_temp = tempfile.gettempdir()
        session_id = f"reel_{niche.replace(' ', '_')[:20]}_{int(time.time())}"
        temp_dir = f"{base_temp}/{session_id}"
        os.makedirs(temp_dir, exist_ok=True)

        # 1. Generate Script
        print("ü§ñ Writing script & visual prompts...")
        content_data = self._generate_ai_script(niche, num_images)
        
        print(f"üìù Title: {content_data['title']}")
        print(f"üéµ Mood: {content_data['mood']}")

        music_path = self._download_music(content_data['mood'])
        
        # 2. Process Segments (Voice -> Image -> Clip)
        video_clips = []
        
        for i, segment in enumerate(content_data['segments']):
            print(f"\nüéûÔ∏è Processing Segment {i+1}/{len(content_data['segments'])}...")
            
            # A. Generate Voiceover
            voice_path = f"{temp_dir}/voice_{i:03d}.mp3"
            print(f"   üó£Ô∏è Generating Voiceover: '{segment['voiceover'][:30]}...'")
            if self._generate_voiceover(segment['voiceover'], voice_path):
                # Calculate duration based on voice
                seg_duration = self._get_audio_duration(voice_path) + 0.3 # +0.3s padding
            else:
                # Fallback silent
                voice_path = None
                seg_duration = 3.0

            # B. Generate Image
            img_path = f"{temp_dir}/img_{i:03d}.jpg"
            print(f"   üé® Generating Image...")
            image_data = self._generate_image(segment['visual_prompt'])
            with open(img_path, 'wb') as f:
                f.write(base64.b64decode(image_data))
                
            # Optional Enhance
            img_path = self._enhance_image_optional(img_path, temp_dir, i)

            # C. Create Individual Clip (Image + Voice)
            clip_path = f"{temp_dir}/clip_{i:03d}.mp4"
            self._create_single_clip(img_path, voice_path, segment['text_overlay'], 
                                     seg_duration, clip_path, i)
            video_clips.append(clip_path)

        # 3. Concatenate and Mix Music
        final_video_path = f"{temp_dir}/reel.mp4"
        self._stitch_and_mix_audio(video_clips, music_path, final_video_path, temp_dir)

        with open(final_video_path, 'rb') as f:
            video_base64 = base64.b64encode(f.read()).decode()

        return {
            'video_base64': video_base64,
            'caption': content_data['caption'],
            'hashtags': content_data['hashtags'],
            'title': content_data['title'],
            'description': content_data['description'],
            'tags': content_data['tags'],
            'category_id': content_data['category_id'],
            'temp_dir': temp_dir
        }

    def _generate_image(self, prompt: str) -> str:
        """Cascading Image Generation (HF Flux -> Pollinations)"""
        
        # 1. Try Hugging Face (Flux.1 Schnell - Best Free Model)
        print("   üîÑ Strategy 1: Flux.1 Schnell (HF)...")
        try:
            return self._huggingface_generate(prompt, model="black-forest-labs/FLUX.1-schnell")
        except:
            pass
            
        # 2. Try Hugging Face (SDXL Lightning - Fast Fallback)
        print("   üîÑ Strategy 2: SDXL Lightning (HF)...")
        try:
            return self._huggingface_generate(prompt, model="ByteDance/SDXL-Lightning")
        except:
            pass

        # 3. Pollinations (Reliable Fallback)
        print("   üîÑ Strategy 3: Pollinations...")
        try:
            return self._pollinations_generate(prompt)
        except Exception as e:
            raise Exception(f"‚ùå All image sources failed. Last error: {e}")

    def _huggingface_generate(self, prompt: str, model: str) -> str:
        enhanced = f"{prompt}, cinematic lighting, 8k, photorealistic, award winning photography, 9:16 aspect ratio"
        API_URL = f"https://api-inference.huggingface.co/models/{model}"
        headers = {"Authorization": f"Bearer {self.huggingface_api_token}"} if self.huggingface_api_token else {}
        
        try:
            response = requests.post(API_URL, headers=headers, json={"inputs": enhanced}, timeout=60)
            if response.status_code == 200 and 'image' in response.headers.get('content-type', ''):
                return base64.b64encode(response.content).decode()
            raise Exception(f"Status {response.status_code}")
        except Exception as e:
            raise e

    def _pollinations_generate(self, prompt: str) -> str:
        enhanced = f"{prompt}, cinematic, 8k, photorealistic"
        encoded = quote(enhanced)
        url = f"https://image.pollinations.ai/prompt/{encoded}?width=1080&height=1920&nologo=true&model=flux"
        
        response = requests.get(url, timeout=60)
        if response.status_code == 200:
            return base64.b64encode(response.content).decode()
        raise Exception("Pollinations failed")

    def _generate_ai_script(self, niche: str, count: int) -> dict:
        """Generate a Coherent Script instead of random scenes"""
        prompt = f"""You are an elite short-form video storyteller. Create a viral script for: {niche}.
        Structure: Hook -> Value/Story -> Conclusion.
        Total Segments: {count}.
        
        JSON Format:
        {{
            "segments": [
                {{
                    "voiceover": "Spoken text for TTS (keep it natural)",
                    "visual_prompt": "Detailed description of the image for this sentence (photorealistic, 4k)",
                    "text_overlay": "Short text on screen (max 5 words)"
                }}
            ],
            "title": "SEO optimized YouTube title (under 100 chars)",
            "caption": "Engaging Instagram caption",
            "hashtags": ["#tag1", "#tag2"],
            "description": "YouTube video description",
            "tags": "tag1, tag2, tag3 (comma separated)",
            "mood": "intense", 
            "category_id": "22"
        }}
        """
        
        json_str = None
        if self.google_api_key:
            try:
                model = genai.GenerativeModel('gemini-2.0-flash-exp')
                response = model.generate_content(prompt)
                json_str = response.text.strip()
            except: pass
            
        if not json_str and self.huggingface_api_token:
             json_str = self._huggingface_text_generate(prompt)
             
        if not json_str: raise Exception("AI Script Generation Failed")
        
        return self._parse_and_validate(json_str, niche, count)

    def _parse_and_validate(self, json_str: str, niche: str, count: int) -> dict:
        # Clean markdown
        if '```json' in json_str: json_str = json_str.split('```json')[1].split('```')[0].strip()
        elif '```' in json_str: json_str = json_str.split('```')[1].split('```')[0].strip()
        
        try:
            data = json.loads(json_str)
            # Basic validation
            if 'segments' not in data: raise ValueError
            return data
        except:
            # Fallback structure
            print("‚ö†Ô∏è JSON Parse failed, using fallback script")
            return {
                "segments": [{"voiceover": f"Here is a fact about {niche}", "visual_prompt": f"{niche} concept art", "text_overlay": niche}] * count,
                "title": f"Facts about {niche}",
                "caption": f"Learn about {niche}",
                "hashtags": ["#viral"],
                "description": "Subscribe for more",
                "tags": "viral, shorts",
                "mood": "upbeat",
                "category_id": "22"
            }

    def _create_single_clip(self, img_path, voice_path, text, duration, output_path, index):
        """Create a single video segment: Image + Zoom + Text + Audio"""
        
        # 1. Filter Complex for Zoom + Text
        vf_chain = f"scale=1080:1920:force_original_aspect_ratio=increase,crop=1080:1920," \
                   f"zoompan=z='min(zoom+0.0015,1.5)':d=700:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)':s=1080x1920:fps=30"
        
        # Add text (Box style with bottom gradient for readability)
        if self.has_drawtext and text:
            # Add a semi-transparent dark box at bottom for text readability
            # Draw text
            text_esc = text.replace("'", "").upper()
            vf_chain += f",drawbox=y=ih-450:color=black@0.4:width=iw:height=200:t=fill," \
                        f"drawtext=text='{text_esc}':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=h-350:shadowcolor=black:shadowx=2:shadowy=2"

        inputs = ['-loop', '1', '-i', img_path]
        
        # Add audio input if voice exists
        if voice_path and os.path.exists(voice_path):
            inputs.extend(['-i', voice_path])
            # Use audio duration
            cmd = ['ffmpeg', '-y'] + inputs + \
                  ['-vf', vf_chain, '-c:v', 'libx264', '-t', str(duration), '-pix_fmt', 'yuv420p',
                   '-shortest', output_path] # -shortest cuts video when audio ends
        else:
            # Silent clip
            cmd = ['ffmpeg', '-y'] + inputs + \
                  ['-vf', vf_chain, '-c:v', 'libx264', '-t', str(duration), '-pix_fmt', 'yuv420p',
                   output_path]

        subprocess.run(cmd, check=True, capture_output=True)

    def _stitch_and_mix_audio(self, clips, music_path, output_path, temp_dir):
        """Concat clips and mix with background music (ducking)"""
        
        # 1. Concat Visuals + Voice
        concat_file = f"{temp_dir}/concat.txt"
        with open(concat_file, 'w') as f:
            for clip in clips:
                f.write(f"file '{clip}'\n")
        
        concat_video = f"{temp_dir}/concat_video.mp4"
        subprocess.run(['ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', concat_file, 
                        '-c', 'copy', concat_video], check=True, capture_output=True)

        # 2. Get total duration
        total_dur = self._get_audio_duration(concat_video)
        
        # 3. Mix Music (Background) + Voice (Foreground)
        # We lower music volume to 0.15 so voice (1.0) is clear
        cmd = [
            'ffmpeg', '-y',
            '-i', concat_video,   # Input 0: Video + Voice
            '-i', music_path,     # Input 1: Music
            '-filter_complex',
            f"[1:a]volume=0.15[bg];[0:a][bg]amix=inputs=2:duration=first[a_out]",
            '-map', '0:v',        # Take video from input 0
            '-map', '[a_out]',    # Take mixed audio
            '-c:v', 'copy',       # Don't re-encode video
            '-c:a', 'aac', '-b:a', '192k',
            '-shortest',          # Stop when video ends
            output_path
        ]
        
        print("üéõÔ∏è Mixing Audio & Rendering Final Video...")
        subprocess.run(cmd, check=True, capture_output=True)

    # --- Utilities ---
    def _download_music(self, mood: str) -> str:
        url = random.choice(self.music_library.get(mood.lower(), self.music_library['upbeat']))
        path = f"{tempfile.gettempdir()}/music.mp3"
        try:
            with open(path, 'wb') as f:
                f.write(requests.get(url, timeout=10).content)
            return path
        except:
            return self._generate_silent_audio()

    def _generate_silent_audio(self) -> str:
        path = f"{tempfile.gettempdir()}/silent.mp3"
        subprocess.run(['ffmpeg', '-y', '-f', 'lavfi', '-i', 'anullsrc=r=44100:cl=stereo', '-t', '10', path], capture_output=True)
        return path
        
    def _enhance_image_optional(self, original_path, temp_dir, index):
        """Optional Cloudinary Enhancement (Keep existing logic or skip)"""
        if not self.enable_enhancement: return original_path
        # (Simplified for brevity - assumes your previous Cloudinary logic here works)
        # If you want the full cloudinary code back, I can paste it, but 
        # for 0-budget, raw Flux/SDXL images are usually good enough.
        return original_path 

class CloudinaryVideoUploader:
    @staticmethod
    def upload_video(video_base64: str, cloud_name: str, upload_preset: str, api_key: str, api_secret: str) -> dict:
        import hashlib
        timestamp = int(time.time())
        params = {'timestamp': timestamp, 'upload_preset': upload_preset}
        string_to_sign = '&'.join(f"{k}={v}" for k, v in sorted(params.items())) + api_secret
        signature = hashlib.sha1(string_to_sign.encode()).hexdigest()
        
        url = f"https://api.cloudinary.com/v1_1/{cloud_name}/video/upload"
        files = {'file': f"data:video/mp4;base64,{video_base64}"}
        data = {'api_key': api_key, 'signature': signature, 'timestamp': timestamp, 'upload_preset': upload_preset}
        
        print("‚òÅÔ∏è Uploading to Cloudinary...")
        resp = requests.post(url, files=files, data=data, timeout=120)
        if resp.status_code != 200: raise Exception(f"Cloudinary Upload Failed: {resp.text}")
        return resp.json()

    @staticmethod
    def delete_video(cloud_name, api_key, api_secret, public_id):
        auth = (api_key, api_secret)
        url = f"https://api.cloudinary.com/v1_1/{cloud_name}/resources/video/upload"
        requests.delete(url, auth=auth, data={'public_ids[]': public_id, 'invalidate': True})

class InstagramReelPublisher:
    def publish_reel(self, account_id, access_token, video_url, caption):
        print("üì± Publishing to Instagram...")
        url = f"https://graph.facebook.com/v20.0/{account_id}/media"
        
        # 1. Create Container
        resp = requests.post(url, data={'media_type': 'REELS', 'video_url': video_url, 'caption': caption, 'access_token': access_token})
        if resp.status_code != 200: raise Exception(f"IG Container Failed: {resp.text}")
        container_id = resp.json()['id']
        
        # 2. Wait for processing
        for _ in range(10):
            time.sleep(5)
            status = requests.get(f"https://graph.facebook.com/v20.0/{container_id}", params={'fields': 'status_code', 'access_token': access_token}).json()
            if status.get('status_code') == 'FINISHED': break
            if status.get('status_code') == 'ERROR': raise Exception("IG Processing Error")
            
        # 3. Publish
        resp = requests.post(f"https://graph.facebook.com/v20.0/{account_id}/media_publish", data={'creation_id': container_id, 'access_token': access_token})
        if resp.status_code != 200: raise Exception(f"IG Publish Failed: {resp.text}")
        return resp.json()['id']

class YouTubePublisher:
    def __init__(self, client_id, client_secret, refresh_token, token_uri):
        print("üì∫ Initializing YouTube...")
        self.creds = Credentials(None, refresh_token=refresh_token, token_uri=token_uri, client_id=client_id, client_secret=client_secret, scopes=['https://www.googleapis.com/auth/youtube.upload'])
        from google.auth.transport.requests import Request
        self.creds.refresh(Request())
        self.youtube = build("youtube", "v3", credentials=self.creds)

    def publish_video(self, video_path, title, description, tags, category_id="22", privacy="public"):
        print(f"üì∫ Uploading to YouTube: {title[:30]}...")
        body = {
            "snippet": {"title": title[:100], "description": description[:5000], "tags": tags.split(',') if isinstance(tags, str) else tags, "categoryId": category_id},
            "status": {"privacyStatus": privacy, "selfDeclaredMadeForKids": False}
        }
        media = MediaFileUpload(video_path, chunksize=256*1024, resumable=True, mimetype='video/mp4')
        req = self.youtube.videos().insert(part="snippet,status", body=body, media_body=media)
        
        resp = None
        while resp is None:
            status, resp = req.next_chunk()
            if status: print(f"   Upload: {int(status.progress() * 100)}%")
        
        print(f"‚úÖ YouTube Upload Success: {resp.get('id')}")
        return resp.get('id')

def main():
    print("üöÄ STARTING 0-BUDGET AI REEL ENGINE")
    
    # Credentials
    conf = {k: os.getenv(k) for k in [
        'GOOGLE_API_KEY', 'OPENAI_API_KEY', 'CLOUDINARY_CLOUD_NAME', 
        'CLOUDINARY_UPLOAD_PRESET', 'CLOUDINARY_API_KEY', 'CLOUDINARY_API_SECRET',
        'INSTAGRAM_ACCOUNT_ID', 'INSTAGRAM_ACCESS_TOKEN', 
        'REPLICATE_API_TOKEN', 'HUGGINGFACE_API_TOKEN',
        'CLIENT_ID_YOUTUBE', 'CLIENT_SECRET_YOUTUBE', 'REFRESH_TOKEN_YOUTUBE'
    ]}
    
    # Initialize Generator
    gen = TrulyAIReelGenerator(
        google_api_key=conf['GOOGLE_API_KEY'],
        openai_api_key=conf['OPENAI_API_KEY'],
        cloudinary_cloud_name=conf['CLOUDINARY_CLOUD_NAME'],
        cloudinary_api_key=conf['CLOUDINARY_API_KEY'],
        cloudinary_api_secret=conf['CLOUDINARY_API_SECRET'],
        cloudinary_upload_preset=conf['CLOUDINARY_UPLOAD_PRESET'],
        replicate_api_token=conf['REPLICATE_API_TOKEN'],
        huggingface_api_token=conf['HUGGINGFACE_API_TOKEN']
    )

    try:
        # Settings
        niche = os.getenv('REEL_NICHE', 'Mind blowing psychological facts')
        # We ignore duration env var because audio dictates duration now
        
        # 1. Generate & Render Video
        result = gen.generate_reel(niche, num_images=int(os.getenv('REEL_IMAGES', '5')))
        
        # 2. Upload Cloudinary
        video_url = None
        public_id = None
        
        try:
            up_res = CloudinaryVideoUploader.upload_video(
                result['video_base64'], conf['CLOUDINARY_CLOUD_NAME'], 
                conf['CLOUDINARY_UPLOAD_PRESET'], conf['CLOUDINARY_API_KEY'], 
                conf['CLOUDINARY_API_SECRET']
            )
            video_url = up_res['secure_url']
            public_id = up_res['public_id']
        except Exception as e:
            print(f"‚ùå Cloudinary Error: {e}")

        # 3. Instagram
        if video_url and conf['INSTAGRAM_ACCESS_TOKEN']:
            try:
                ig = InstagramReelPublisher()
                caption = f"{result['caption']}\n\n{' '.join(result['hashtags'])}"
                ig.publish_reel(conf['INSTAGRAM_ACCOUNT_ID'], conf['INSTAGRAM_ACCESS_TOKEN'], video_url, caption)
                print("‚úÖ Instagram Published!")
                
                # Cleanup Cloudinary
                time.sleep(10)
                CloudinaryVideoUploader.delete_video(conf['CLOUDINARY_CLOUD_NAME'], conf['CLOUDINARY_API_KEY'], conf['CLOUDINARY_API_SECRET'], public_id)
            except Exception as e:
                print(f"‚ùå Instagram Error: {e}")

        # 4. YouTube
        if conf['REFRESH_TOKEN_YOUTUBE']:
            try:
                yt = YouTubePublisher(
                    conf['CLIENT_ID_YOUTUBE'], conf['CLIENT_SECRET_YOUTUBE'], 
                    conf['REFRESH_TOKEN_YOUTUBE'], "https://oauth2.googleapis.com/token"
                )
                yt.publish_video(
                    f"{result['temp_dir']}/reel.mp4",
                    result['title'],
                    result['description'],
                    result['tags'],
                    result['category_id']
                )
            except Exception as e:
                 print(f"‚ùå YouTube Error: {e}")
                 
    except Exception as e:
        print(f"‚ùå FATAL ERROR: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
